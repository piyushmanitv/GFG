Longest Span in two Binary Arrays
Difficulty: MediumAccuracy: 48.22%Submissions: 14K+Points: 4
Given two binary arrays, a1[] and a2[]. Find the length of longest common span (i, j) where j>= i such that a1[i] + a1[i+1] + .... + a1[j] =  a2[i] + a2[i+1] + ... + a2[j].









  class Solution {
  public:
    int longestCommonSum(vector<int> &a1, vector<int> &a2) {
        int n = a1.size();
        unordered_map<int, int> mp;
        int maxLen = 0;
        int currSum = 0;
        
        for (int i = 0; i < n; i++) {
            currSum += a1[i] - a2[i];

            if (currSum == 0)
                maxLen = i + 1;

            if (mp.find(currSum) != mp.end()) {
                maxLen = max(maxLen, i - mp[currSum]);
            } else {
                mp[currSum] = i;
            }
        }

        return maxLen;
    }
};
